{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5240e458-2ca9-4cfb-b035-53749246a3b0",
   "metadata": {},
   "source": [
    "Towards 3D Deep Learning for neuropsychiatry: predicting Autism diagnosis using an interpretable Deep Learning pipeline applied to minimally processed structural MRI data, Melanie Garcia, Clare Kelly. medRxiv 2022.10.18.22281196; doi: https://doi.org/10.1101/2022.10.18.22281196\n",
    "\n",
    "Github: https://github.com/garciaml/Autism-3D-CNN-brain-sMRI?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b7162-4d1a-433b-8e99-ed09c93fee22",
   "metadata": {},
   "source": [
    "# Activate Virtual Environment and Install Requirements\n",
    "!python3 -m venv ../pretrainedresnet2\n",
    "!source ../pretrainedresnet2/bin/activate\n",
    "!python3 -m ipykernel install --user --name=pretrainedresnet2 --display-name \"Python (pretrainedresnet2)\"\n",
    "#Switch to notebook/virtual environment kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d921c-63b9-4ebb-8d8b-9168797104b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training from scratch - Use ABIDE 1 \n",
    "# larger batch sizes (2 -> 4)\n",
    "# larger learning rate (0.001 -> 0.01)\n",
    "# seed change (0 -> 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0d951-d4a2-4b3c-843c-955456a053ac",
   "metadata": {},
   "source": [
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d975799-f225-4d87-b441-d777b96bc00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "Loading pretrained model weights selectively (backbone)\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(pretrain_path, map_location=device)\n",
      "Layer: 0, Parameter: 0.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.downsample.0.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.downsample.1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.0.downsample.1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.1.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer1.2.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.downsample.0.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.downsample.1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.0.downsample.1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.1.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.2.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer2.3.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.downsample.0.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.downsample.1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.0.downsample.1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.1.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.2.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.3.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.4.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.conv1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn1.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn1.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.conv2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn2.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn2.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.conv3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn3.weight, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer3.5.bn3.bias, Requires_grad: False\n",
      "Layer: 0, Parameter: 0.layer4.0.conv1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn1.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.conv2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn2.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.conv3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.bn3.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.downsample.0.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.downsample.1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.0.downsample.1.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.conv1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn1.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.conv2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn2.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.conv3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.1.bn3.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.conv1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn1.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn1.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.conv2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn2.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn2.bias, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.conv3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn3.weight, Requires_grad: True\n",
      "Layer: 0, Parameter: 0.layer4.2.bn3.bias, Requires_grad: True\n",
      "Layer: 3, Parameter: 3.weight, Requires_grad: True\n",
      "Layer: 3, Parameter: 3.bias, Requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "!python ../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py 'JustBrain_Data/ABIDE1' 'Preprocessed_Data/ABIDE1' './outputs/Resnet50/ABIDE1' '../Autism-3D-CNN-brain-sMRI/resnet_training/resnet_50.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba05730-628b-4409-b776-cd6405f53223",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "Loading pretrained model weights selectively (backbone)\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrained_weights = torch.load(pretrain_path, map_location=device)\n",
      "----------\n",
      "epoch 1\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Traceback (most recent call last):\n",
      "  File \"/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py\", line 162, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/home/ejh2wy/.local/lib/python3.11/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/ejh2wy/.local/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/ejh2wy/.local/lib/python3.11/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 207.06 MiB is free. Including non-PyTorch memory, this process has 10.51 GiB memory in use. Of the allocated memory 9.42 GiB is allocated by PyTorch, and 909.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!python ../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py 'JustBrain_Data/ABIDE1' 'Preprocessed_Data/ABIDE1' './outputs/Resnet50/ABIDE1' '../Autism-3D-CNN-brain-sMRI/resnet_training/resnet_50.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68d4b4-c8cd-40c1-bf10-90110e6cf848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resume training from saved model\n",
    "!python ../Autism-3D-CNN-brain-sMRI/train_medicalnet_update.py 'JustBrain_Data/ABIDE_COMBINED' 'Preprocessed_Data/ABIDE_COMBINED' './outputs/Resnet50/ABIDE_Combined' 'outputs/Resnet50/ABIDE_Combined/checkpoint_30.pth' --resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8654e748-5af5-4e97-8e72-94e4925eed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/Resnet50/ABIDE1/training.log\", \"r\") as infile, open(\"outputs/Resnet50/ABIDE1/filtered.log\", \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        if line.startswith(\"epoch \") and \"average loss\" in line:\n",
    "            outfile.write(line)\n",
    "        elif line.startswith(\"current epoch:\"):\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1343affc-7c63-48a6-9312-159e93768c1d",
   "metadata": {},
   "source": [
    "# ABIDEII"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8499e-064d-401b-bb7c-215be375d59c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75547e36-4142-43eb-89aa-296adb7b1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'test']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/test/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3dae81f-48e7-4cea-8b32-32cdec2fca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain = torch.load(pretrain_path)\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "evaluation metric: 0.48695652173913045\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 36 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/test' 'outputs/Resnet50/ABIDE_Combined/test/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_36.pth' './outputs/Resnet50/ABIDE_Combined/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ab0961b-f52b-4b88-a5c9-8f5a470a31cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain = torch.load(pretrain_path)\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "evaluation metric: 0.48695652173913045\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 12 and 8 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/test' 'outputs/Resnet50/ABIDE_Combined/test/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_12.pth' './outputs/Resnet50/ABIDE_Combined/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852ab040-6f42-42ae-bdde-43f6b43257c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain = torch.load(pretrain_path)\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "evaluation metric: 0.48695652173913045\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 2 epochs (still just predicting 0s)\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/test' 'outputs/Resnet50/ABIDE_Combined/test/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_2.pth' './outputs/Resnet50/ABIDE_Combined/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a820afc-d2d9-4766-9d87-742fee1f72d4",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3ec65f-8e20-4e35-9ac4-9620001b4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'val']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/validation/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cb6d4-8eb4-4906-a70c-ea24d2a72576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions - 36 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/val' 'outputs/Resnet50/ABIDE_Combined/validation/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_36.pth' './outputs/Resnet50/ABIDE_Combined/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8787f-2a50-4e27-a83e-c1ec01db9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions - 12 epochs\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/val' 'outputs/Resnet50/ABIDE_Combined/validation/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_12.pth' './outputs/Resnet50/ABIDE_Combined/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75b94b-163d-49a2-ac9e-1760de5b7051",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2267488-6795-4724-92d7-c5ea9d648c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'train']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/train/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5ce33b-b322-4708-ba77-397ecce85708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain = torch.load(pretrain_path)\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "evaluation metric: 0.5294464075382803\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 36 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/train' 'outputs/Resnet50/ABIDE_Combined/train/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_36.pth' './outputs/Resnet50/ABIDE_Combined/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5a5a5-e742-46eb-bdd9-33da80889328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions - 12 epochs\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/train' 'outputs/Resnet50/ABIDE_Combined/train/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_12.pth' './outputs/Resnet50/ABIDE_Combined/train'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretrainedresnet2)",
   "language": "python",
   "name": "pretrainedresnet2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
