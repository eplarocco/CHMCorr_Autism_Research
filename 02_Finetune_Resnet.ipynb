{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "189dee69-b4b1-4ce8-ae2b-a71da560b8d0",
   "metadata": {},
   "source": [
    "# Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5240e458-2ca9-4cfb-b035-53749246a3b0",
   "metadata": {},
   "source": [
    "Towards 3D Deep Learning for neuropsychiatry: predicting Autism diagnosis using an interpretable Deep Learning pipeline applied to minimally processed structural MRI data, Melanie Garcia, Clare Kelly. medRxiv 2022.10.18.22281196; doi: https://doi.org/10.1101/2022.10.18.22281196\n",
    "\n",
    "Github: https://github.com/garciaml/Autism-3D-CNN-brain-sMRI?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05524cd2-b4c5-4a16-a5d5-9cd438e8ebcc",
   "metadata": {},
   "source": [
    "# Virtual Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e3403-af0b-48b5-ae17-b4f95cb37f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate Virtual Environment and Install Requirements\n",
    "#!python3 -m venv ../pretrainedresnet2\n",
    "#!source ../pretrainedresnet2/bin/activate\n",
    "#!python3 -m ipykernel install --user --name=pretrainedresnet2 --display-name \"Python (pretrainedresnet2)\"\n",
    "#Switch to notebook/virtual environment kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43988b7f-38d8-48dc-8eff-0e85bdc20bb5",
   "metadata": {},
   "source": [
    "# Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580654c-8995-41ac-8a45-b1d3be5d3827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt\n",
    "#!pip install \"torchio>=0.19.0\"\n",
    "#!pip install monai\n",
    "#!pip install tensorboard\n",
    "#!pip install torchsummary\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca8835-3e91-422a-9ea8-2ca9eddff78a",
   "metadata": {},
   "source": [
    "# Functions for Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf232768-d708-4975-940a-21a4a1c34239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_with_structure(source_folder, destination_folder):\n",
    "    \"\"\"Copies the contents of source_folder to destination_folder, maintaining the directory structure.\"\"\"\n",
    "\n",
    "    for item in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, item)\n",
    "        destination_path = os.path.join(destination_folder, item)\n",
    "\n",
    "        if os.path.isfile(source_path):\n",
    "            shutil.copy2(source_path, destination_path)  # copy file with metadata\n",
    "        elif os.path.isdir(source_path):\n",
    "             shutil.copytree(source_path, destination_path, dirs_exist_ok=True) # copy directory and its contents\n",
    "        else:\n",
    "            print(f\"Skipping {source_path}, not a file or directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015997f8-e4a4-4328-aa85-d093a64e9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_folders(path):\n",
    "    folder_count = 0\n",
    "    for item in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, item)):\n",
    "            folder_count += 1\n",
    "    return folder_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e980f0-c81c-48bf-aff6-ec53256386f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(directory_path):\n",
    "    \"\"\"Counts the number of files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path: The path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        The number of files in the directory, or -1 if the directory does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        return -1\n",
    "    \n",
    "    file_count = 0\n",
    "    for item in os.listdir(directory_path):\n",
    "        item_path = os.path.join(directory_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            file_count += 1\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c87d2cb-dd55-4fbc-a97a-8e6b39214239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_autism_labels(filepath):\n",
    "    # Load the TSV file\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep='\\t')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check required columns\n",
    "    required_columns = {'label', 'dataset'}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        print(f\"Missing required columns. Found columns: {df.columns.tolist()}\")\n",
    "        return\n",
    "\n",
    "    # Debug: print unique values\n",
    "    print(\"Unique labels:\", df['label'].unique())\n",
    "    print(\"Unique dataset entries:\", df['dataset'].unique())\n",
    "\n",
    "    # Convert numeric labels to string labels\n",
    "    label_map = {1: 'Autism', 0: 'No Autism'}\n",
    "    df['label'] = df['label'].map(label_map)\n",
    "\n",
    "    if df['label'].isnull().any():\n",
    "        print(\"Warning: Some labels could not be mapped (not 0 or 1).\")\n",
    "\n",
    "    # Count labels per dataset split\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        subset = df[df['dataset'] == split]\n",
    "        if subset.empty:\n",
    "            print(f\"No data for split: {split}\")\n",
    "            continue\n",
    "\n",
    "        autism_count = (subset['label'] == 'Autism').sum()\n",
    "        no_autism_count = (subset['label'] == 'No Autism').sum()\n",
    "\n",
    "        print(f\"{split.upper()} SET:\")\n",
    "        print(f\"  Autism: {autism_count}\")\n",
    "        print(f\"  No Autism: {no_autism_count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5127b43-a41c-49ce-93c2-0989a59014fb",
   "metadata": {},
   "source": [
    "# Combine ABIDE Datasets for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b7d69-2a82-4d14-b9a4-bb0194d36612",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Copy ABIDE1 and ABIDE2 images to ABIDE_COMBINED folder in JustBrain_Data folder\n",
    "source_folder1 = \"JustBrain_Data/ABIDE1\"\n",
    "source_folder2 = \"JustBrain_Data/ABIDE2\"\n",
    "destination_folder = \"JustBrain_Data/ABIDE_COMBINED\"\n",
    "\n",
    "copy_with_structure(source_folder1, destination_folder)\n",
    "copy_with_structure(source_folder2, destination_folder)\n",
    "\n",
    "\n",
    "#Combine ABIDEI and ABIDE2 tsv files\n",
    "participants1_tsv = pd.read_csv('JustBrain_Data/ABIDE1/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants1_tsv['participant_id'] = participants1_tsv['participant_id'].astype(str).str.zfill(7)\n",
    "participants2_tsv = pd.read_csv('JustBrain_Data/ABIDE2/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_ABIDE = pd.concat([participants1_tsv,participants2_tsv])\n",
    "participants_ABIDE.to_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep='\\t', index=False, header=True)\n",
    "\n",
    "#Check\n",
    "print(count_folders(source_folder1) + count_folders(source_folder2))\n",
    "print(count_folders(destination_folder))\n",
    "print(participants_ABIDE.shape[0]) # - looks good!\n",
    "\n",
    "\n",
    "#Copy ABIDE1 and ABIDE2 images to ABIDE_COMBINED folder in Preprocessed_Data folder\n",
    "source_folder1 = \"Preprocessed_Data/ABIDE1\"\n",
    "source_folder2 = \"Preprocessed_Data/ABIDE2\"\n",
    "destination_folder = \"Preprocessed_Data/ABIDE_COMBINED\"\n",
    "\n",
    "copy_with_structure(source_folder1, destination_folder)\n",
    "copy_with_structure(source_folder2, destination_folder)\n",
    "\n",
    "#Check\n",
    "test_folder = count_files(\"Preprocessed_Data/ABIDE_COMBINED/test\")\n",
    "train_folder = count_files(\"Preprocessed_Data/ABIDE_COMBINED/train\")\n",
    "val_folder = count_files(\"Preprocessed_Data/ABIDE_COMBINED/val\")\n",
    "print(test_folder + train_folder + val_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e64091-9706-41c1-a4ed-e38bcb68a996",
   "metadata": {},
   "source": [
    "# Check Label Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f0677f8-8b47-4927-8618-3bab5d813a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [1 0]\n",
      "Unique dataset entries: ['train' 'val' 'test']\n",
      "TRAIN SET:\n",
      "  Autism: 799\n",
      "  No Autism: 899\n",
      "\n",
      "VAL SET:\n",
      "  Autism: 142\n",
      "  No Autism: 157\n",
      "\n",
      "TEST SET:\n",
      "  Autism: 59\n",
      "  No Autism: 56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_autism_labels('JustBrain_Data/ABIDE_COMBINED/participants.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df1fbc-0080-431c-93ec-610df1031bfe",
   "metadata": {},
   "source": [
    "# Check input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6102277-b273-45ca-95f0-976d80f1ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 256)\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : np.bytes_(b'')\n",
      "db_name         : np.bytes_(b'')\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : np.bytes_(b'')\n",
      "dim_info        : 0\n",
      "dim             : [  4   1 256 256 256   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1.  1.5 1.5 1.5 1.  1.  1.  1. ]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : np.bytes_(b'')\n",
      "aux_file        : np.bytes_(b'')\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : -0.00018888905\n",
      "quatern_c       : 0.009038601\n",
      "quatern_d       : -0.020892622\n",
      "qoffset_x       : -202.16577\n",
      "qoffset_y       : -177.70763\n",
      "qoffset_z       : -170.72014\n",
      "srow_x          : [ 1.4984454e+00  6.2656499e-02  2.7120616e-02 -2.0216577e+02]\n",
      "srow_y          : [-6.2666751e-02  1.4986904e+00  0.0000000e+00 -1.7770763e+02]\n",
      "srow_z          : [-2.7096936e-02 -1.1330405e-03  1.4997548e+00 -1.7072014e+02]\n",
      "intent_name     : np.bytes_(b'')\n",
      "magic           : np.bytes_(b'n+1')\n"
     ]
    }
   ],
   "source": [
    "import nilearn\n",
    "from nilearn.image import load_img\n",
    "from nilearn.image import math_img\n",
    "from nilearn import plotting, datasets\n",
    "\n",
    "# Preprocessed Image\n",
    "image_path = 'Preprocessed_Data/ABIDE_COMBINED/train/29582_prep.nii.gz' #random image - in correct format\n",
    "\n",
    "# Load Image\n",
    "img = nilearn.image.load_img(image_path)\n",
    "\n",
    "# Data\n",
    "print(img.get_fdata().shape)\n",
    "print(img.header)\n",
    "\n",
    "# Plot\n",
    "#plotting.plot_img(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6f52b-613f-4634-a61e-95b3a7c277d8",
   "metadata": {},
   "source": [
    "# Finetune Model from Pretrained Medical ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597d68a7-58a1-4ec3-923b-39beeadcee5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model weights from Resnet50 (backbone)\n",
      "----------\n",
      "epoch 1\n",
      "epoch 1 average loss: 0.7480\n",
      "Epoch time duration: 536.5190982818604\n",
      "current epoch: 1 current accuracy: 0.4749 best accuracy: 0.4749 at epoch 1\n",
      "----------\n",
      "epoch 2\n",
      "epoch 2 average loss: 0.7204\n",
      "Epoch time duration: 543.4542438983917\n",
      "current epoch: 2 current accuracy: 0.5485 best accuracy: 0.5485 at epoch 2\n",
      "----------\n",
      "epoch 3\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Start training from scratch\n",
    "!python ../Autism-3D-CNN-brain-sMRI/train_medicalnet.py 'JustBrain_Data/ABIDE_COMBINED' 'Preprocessed_Data/ABIDE_COMBINED' './outputs/Resnet50/ABIDE_Combined' '../Autism-3D-CNN-brain-sMRI/resnet_training/resnet_10.pth' --lr 0.0003 --batch 8 --epochs 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993877a-8db0-45f1-a64b-f949df2eb724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resume training from saved model\n",
    "#!python ../Autism-3D-CNN-brain-sMRI/train_medicalnet.py 'JustBrain_Data/ABIDE_COMBINED' 'Preprocessed_Data/ABIDE_COMBINED' './outputs/Resnet50/ABIDE_Combined' 'outputs/Resnet50/ABIDE_Combined/checkpoint_1.pth' --resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8499e-064d-401b-bb7c-215be375d59c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75547e36-4142-43eb-89aa-296adb7b1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'test']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/test/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3dae81f-48e7-4cea-8b32-32cdec2fca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation metric: 0.5130434782608696\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 18 epochs (best accuracy) - overfit - predicts 0 for everything\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/test' 'outputs/Resnet50/ABIDE_Combined/test/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_18.pth' './outputs/Resnet50/ABIDE_Combined/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a820afc-d2d9-4766-9d87-742fee1f72d4",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3ec65f-8e20-4e35-9ac4-9620001b4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'val']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/validation/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cb6d4-8eb4-4906-a70c-ea24d2a72576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions - 36 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/val' 'outputs/Resnet50/ABIDE_Combined/validation/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_36.pth' './outputs/Resnet50/ABIDE_Combined/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75b94b-163d-49a2-ac9e-1760de5b7051",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2267488-6795-4724-92d7-c5ea9d648c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_tsv = pd.read_csv('JustBrain_Data/ABIDE_COMBINED/participants.tsv', sep=\"\\t\", dtype=str)\n",
    "participants_tsv.rename(columns={\"participant_id\" : \"SUB_ID\"}, inplace=True)\n",
    "participants_tsv = participants_tsv[participants_tsv.dataset == 'train']\n",
    "participants_tsv.to_csv('outputs/Resnet50/ABIDE_Combined/train/subjects.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5ce33b-b322-4708-ba77-397ecce85708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ejh2wy/Autism-3D-CNN-brain-sMRI/resnet2.py:174: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/sfs/gpfs/tardis/home/ejh2wy/CHMCorr_Autism_Research/../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py:104: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pretrain = torch.load(pretrain_path)\n",
      "/home/ejh2wy/.local/lib/python3.11/site-packages/torchio/data/image.py:248: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/TorchIO-project/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "evaluation metric: 0.5294464075382803\n"
     ]
    }
   ],
   "source": [
    "# Predictions - 36 epochs (predictions all 0) - overfit\n",
    "!python ../Autism-3D-CNN-brain-sMRI/predict_medicalnet_subids.py 'Preprocessed_Data/ABIDE_COMBINED/train' 'outputs/Resnet50/ABIDE_Combined/train/subjects.csv' './outputs/Resnet50/ABIDE_Combined/checkpoint_36.pth' './outputs/Resnet50/ABIDE_Combined/train'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretrainedresnet2)",
   "language": "python",
   "name": "pretrainedresnet2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
